{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\a324150\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\a324150\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: regex in c:\\users\\a324150\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\a324150\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\a324150\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\A324150\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\A324150\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a variável texto a seguir para identificar as stop words\n",
    "e após isso aplique o cáculo do **TF-IDF** neste mesmo texto e observe os scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS:** Para realizar essa tarefa utilize os módulos estudados na aula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Um carro azul seguia rapidamente em uma rodovia, e ao passar por um buraco, o carro furou o pneu, e o motorista desceu do carro azul'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar as \"Stop Words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "stopwords_portuguese = nltk.corpus.stopwords.words('portuguese')\n",
    "print(stopwords_portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ao      azul    buraco     carro    desceu        do        em  \\\n",
      "0  0.179605  0.359211  0.179605  0.538816  0.179605  0.179605  0.179605   \n",
      "\n",
      "      furou  motorista    passar      pneu       por  rapidamente   rodovia  \\\n",
      "0  0.179605   0.179605  0.179605  0.179605  0.179605     0.179605  0.179605   \n",
      "\n",
      "     seguia        um       uma  \n",
      "0  0.179605  0.359211  0.179605  \n"
     ]
    }
   ],
   "source": [
    "#Aplicar Método TF-IDF\n",
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "vector = tf_idf.fit_transform([texto])\n",
    "\n",
    "vector = vector.todense()\n",
    "\n",
    "word_labels = tf_idf.get_feature_names()\n",
    "\n",
    "df = pd.DataFrame(vector,columns = word_labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Método TF-IDF filtrando as Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interessante notarmos que no caso do \"Um\" no início da frase, em virtude da sua letra maiúscula não foi considerado na limpeza do Stop Words, apesar de ser uma.\n",
      " \n",
      "       azul    buraco     carro    desceu     furou  motorista    passar  \\\n",
      "0  0.417029  0.208514  0.625543  0.208514  0.208514   0.208514  0.208514   \n",
      "\n",
      "       pneu  rapidamente   rodovia    seguia        um  \n",
      "0  0.208514     0.208514  0.208514  0.208514  0.208514  \n",
      "\n",
      "Temos como palavras mais relevantes para o método : carro e azul\n"
     ]
    }
   ],
   "source": [
    "texto2 = 'Um carro azul seguia rapidamente em uma rodovia, e ao passar por um buraco, o carro furou o pneu, e o motorista desceu do carro azul'\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "new_texto_teste =[]\n",
    "tokens = word_tokenize(texto2)\n",
    "# Filtro das Stop Words e aplicação em uma nova lista\n",
    "for t in tokens:\n",
    "    if t not in stopwords_portuguese:\n",
    "        new_texto_teste.append(t)\n",
    "#Conversão da Lista para uma Sentença\n",
    "word_list = new_texto_teste        \n",
    "new_texto = \" \".join(word_list)\n",
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "vector = tf_idf.fit_transform([new_texto])\n",
    "\n",
    "vector = vector.todense()\n",
    "\n",
    "word_labels = tf_idf.get_feature_names()\n",
    "\n",
    "df = pd.DataFrame(vector,columns = word_labels)\n",
    "print('Interessante notarmos que no caso do \"Um\" no início da frase, em virtude da sua letra maiúscula não foi considerado na limpeza do Stop Words, apesar de ser uma.\\n ')\n",
    "print(df)\n",
    "print('\\nTemos como palavras mais relevantes para o método : carro e azul')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
